{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import io\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare global variables\n",
    "GCP_KEY = '/home/jupyter/secrets/ac215.json'\n",
    "GCP_DATA_BUCKET = 'data-lnt'\n",
    "GCP_SOURCE_FILENAME = 'raw/unlabeled.csv'\n",
    "OUTPUT_FILEPATH = 'processed/vader_labeled_initial.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create GCP Client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GCP_KEY\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(GCP_DATA_BUCKET)\n",
    "source_filename = GCP_SOURCE_FILENAME\n",
    "blob = bucket.blob(source_filename)\n",
    "content = blob.download_as_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(dataframe):\n",
    "    \"\"\"\n",
    "    Uses NLTK's VADER to evaluate the unlabeled dataset. Labels are added \n",
    "    to the dataframe based on the label provided by the model.\n",
    "\n",
    "    Input: tokenized_texts, model, device, dataframe, batch_size\n",
    "    Output: None\n",
    "    \"\"\"  \n",
    "    #define sentiment analyzer from NLTK Vader\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    #get all text from dataframe\n",
    "    mentions = dataframe['text'].tolist()\n",
    "\n",
    "    #define list to store all labels\n",
    "    labels = []\n",
    "\n",
    "    #loop through all mentions\n",
    "    for mention in mentions:\n",
    "\n",
    "        #Evaluate sentiment of text\n",
    "        sentiment_scores = analyzer.polarity_scores(mention)\n",
    "        \n",
    "        #use compound score to determine final label (negative, neutral, positive)\n",
    "        compound_score = sentiment_scores['compound']\n",
    "\n",
    "        if compound_score <= -0.05:\n",
    "            label = 0\n",
    "        elif compound_score >= 0.05:\n",
    "            label = 2\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        #write label to full label list\n",
    "        labels.append(label)\n",
    "\n",
    "    dataframe['label'] = labels\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataframe, outfilepath):\n",
    "    \"\"\"\n",
    "    Saves the labeled dataframe to GCP data bucket\n",
    "    \n",
    "    Input: Pandas dataframe, GCP file path\n",
    "    Output: None\n",
    "\n",
    "    >>> save_dataset(dataframe, 'filepath'):\n",
    "    returns None\n",
    "    \"\"\"\n",
    "    #convert DataFrame to a CSV string\n",
    "    csv_string = dataframe.to_csv(index=False)\n",
    "\n",
    "    #upload the CSV string to GCP\n",
    "    blob = bucket.blob(outfilepath)\n",
    "    blob.upload_from_string(csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import unlabeled dataset into dataframe\n",
    "df = pd.read_csv(io.StringIO(content))\n",
    "df = df.dropna()\n",
    "#Sanity check\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the dataset\n",
    "df = label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataframe to GCP\n",
    "save_dataset(df, OUTPUT_FILEPATH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
