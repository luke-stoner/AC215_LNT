{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertForSequenceClassification, BertTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.functional import softmax\n",
    "from google.cloud import storage \n",
    "import io\n",
    "import tempfile\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare global variables\n",
    "GCP_KEY = '/home/jupyter/secrets/ac215.json'\n",
    "GCP_DATA_BUCKET = 'data-lnt'\n",
    "GCP_SOURCE_FILENAME = 'processed/labeled_initial.csv'\n",
    "GCP_MODELS_BUCKET = 'models-lnt'\n",
    "\n",
    "HIGH_CONFIDENCE_THRESHOLD = 0.7\n",
    "TEST_SIZE = 0.2\n",
    "NUMBER_EPOCHS = 3\n",
    "RANDOM_STATE = 215\n",
    "ADAM_LEARNING_RATE = 1e-5\n",
    "ADAM_BATCH_SIZE = 32\n",
    "LABEL_BATCH_SIZE = 32\n",
    "\n",
    "MODEL_DIR_FINETUNE = 'fine_tune_label'\n",
    "MODEL_DIR_BERT = 'cardiffnlp/twitter-xlm-roberta-base-sentiment'\n",
    "\n",
    "GCP_OUTPUT_PATH = 'processed/labeled_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create GCP Client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GCP_KEY\n",
    "source_filename = GCP_SOURCE_FILENAME\n",
    "storage_client = storage.Client()\n",
    "data_bucket = storage_client.bucket(GCP_DATA_BUCKET)\n",
    "models_bucket = storage_client.bucket(GCP_MODELS_BUCKET)\n",
    "blob = data_bucket.blob(GCP_SOURCE_FILENAME)\n",
    "content = blob.download_as_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to the first available GPU\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    # If no GPU is available, use the CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_directory):\n",
    "    \"\"\"\n",
    "    Input: model_name (name of desired BERT model)\n",
    "    Output: tokenizer, model\n",
    "\n",
    "    >>> get_model(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "    tokenizer(model_name), model(model_name)\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_directory).to(device)\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_confidence_df(df, threshold=HIGH_CONFIDENCE_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Filters an input dataframe to only include samples with label confidence above a defined threshold\n",
    "\n",
    "    Input: dataframe with initial labels, desired confidence threshold\n",
    "    Output: dataframe including only high confidence examples above specified threshold\n",
    "\n",
    "    >>> get_high_confidence_df(df, 0.9)\n",
    "    high_confidence_df\n",
    "    \"\"\"\n",
    "    return df[(df['negative_score'] > threshold) |\n",
    "    (df['neutral_score'] > threshold) |\n",
    "    (df['positive_score'] > threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(dataframe):\n",
    "    \"\"\"\n",
    "    Returns tokenized text given a dataframe\n",
    "\n",
    "    Input: Pandas dataframe (assumes text column = 'text')\n",
    "    Output: tokenized text\n",
    "\n",
    "    >>> tokenize(df)\n",
    "    tokenized_texts\n",
    "    \"\"\"\n",
    "    text_samples = dataframe['text'].tolist()\n",
    "    tokenized_texts = tokenizer(text_samples, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(df, tokenizer, test_size=TEST_SIZE):\n",
    "    \"\"\"\n",
    "    Returns training and validation datasets given a dataframe and tokenizer\n",
    "\n",
    "    Input: panadas dataframe, tokenizer, \n",
    "    Output: tokenized text\n",
    "\n",
    "    >>> tokenize(df)\n",
    "    tokenized_texts\n",
    "    \"\"\"\n",
    "    # Define training and valid dataframes\n",
    "    train_df, valid_df = train_test_split(df, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Tokenize the training data\n",
    "    train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "    train_labels = torch.tensor(train_df['initial_sentiment'].tolist())\n",
    "\n",
    "    # Tokenize the validation data\n",
    "    valid_encodings = tokenizer(valid_df['text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "    valid_labels = torch.tensor(valid_df['initial_sentiment'].tolist())\n",
    "\n",
    "    # Create DataLoader objects\n",
    "    train_dataset = TensorDataset(train_encodings.input_ids, train_encodings.attention_mask, train_labels)\n",
    "    valid_dataset = TensorDataset(valid_encodings.input_ids, valid_encodings.attention_mask, valid_labels)\n",
    "\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(model, train_dataset, valid_dataset, device, epochs=NUMBER_EPOCHS):\n",
    "    \"\"\"\n",
    "    Fine tunes the pretrained BERT model based on the high confidence samples\n",
    "\n",
    "    Input: BERT model, training dataset, validation dataset, number of epochs\n",
    "    Output: None (Prints epoch progress)\n",
    "\n",
    "    >>> train_bert(high_confidence_df, train_data, valid_data, epochs=4)\n",
    "    Epoch 2/4: Validation Loss: 12.3452, Validation Accuracy: 0.8362\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train loop\n",
    "    optimizer = AdamW(model.parameters(), lr=ADAM_LEARNING_RATE)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=ADAM_BATCH_SIZE, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Validation loop\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=ADAM_BATCH_SIZE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in valid_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        average_loss = total_loss / len(valid_loader)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}: Validation Loss: {average_loss:.4f}, Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_directory, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Saves the final fine tuned model and tokenizer to GCP models bucket\n",
    "\n",
    "    Input: GCP output directory, model, tokenizer\n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    # Create a temporary directory\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        \n",
    "        # Serialize and save the model in the temporary directory\n",
    "        model_path = os.path.join(temp_dir, 'model.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Save the tokenizer in the temporary directory\n",
    "        tokenizer.save_pretrained(temp_dir)\n",
    "\n",
    "        # Upload the serialized model to the GCS bucket\n",
    "        model_blob = models_bucket.blob(f'{output_directory}/model.pth')\n",
    "        model_blob.upload_from_filename(model_path)\n",
    "\n",
    "        # Upload the contents of the temporary directory to the GCS bucket\n",
    "        for root, dirs, files in os.walk(temp_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                gcs_path = f'{output_directory}/{os.path.relpath(file_path, start=temp_dir)}'\n",
    "                blob = models_bucket.blob(gcs_path)\n",
    "                blob.upload_from_filename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def label(tokenized_texts, model, device, dataframe, batch_size=64):\n",
    "    \"\"\"\n",
    "    Uses the fine-tuned model to evaluate the labeled dataset. Sentiment scores and labels are added \n",
    "    to the dataframe based on the label provided by the model.\n",
    "\n",
    "    Input: tokenized_texts, model, device, dataframe, batch_size\n",
    "    Output: None\n",
    "    \"\"\"  \n",
    "    #get input IDs and attention mask from tokenized text\n",
    "    input_ids = tokenized_texts['input_ids'].to(device)\n",
    "    attention_mask = tokenized_texts['attention_mask'].to(device)\n",
    "    \n",
    "    #define dataset from input IDs and attention mask\n",
    "    dataset = TensorDataset(input_ids, attention_mask)\n",
    "\n",
    "    #define batch size and create DataLoader\n",
    "    batch_size = batch_size\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    #set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    #create empty list to store labels for entire dataset\n",
    "    labels = []\n",
    "    \n",
    "    #create a progress bar to track labeling process\n",
    "    progress_bar = tqdm(total=len(dataloader), desc=\"Labeling\")\n",
    "    \n",
    "    for batch_input_ids, batch_attention_mask in dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        \n",
    "        #get output logits and convert to label confidence\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        #append batch labels to dataset label list\n",
    "        batch_labels = torch.softmax(logits, dim=1)\n",
    "        labels.append(batch_labels)\n",
    "        \n",
    "        #update progress bar\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    #concatenate all labels\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    #move labels to CPU to append to dataframe\n",
    "    labels = labels.cpu()\n",
    "    \n",
    "    #extract the raw scores for each sentiment class\n",
    "    negative_scores = [score[0].item() for score in labels]\n",
    "    neutral_scores = [score[1].item() for score in labels]\n",
    "    positive_scores = [score[2].item() for score in labels]\n",
    "    \n",
    "    #define final sentiment label my max of sentiment scores\n",
    "    initial_sentiment = []\n",
    "    for neg, neut, pos in zip(negative_scores, neutral_scores, positive_scores):\n",
    "        initial_sentiment.append([neg, neut, pos].index(max([neg, neut, pos])))\n",
    "\n",
    "    #append the scores and predicted labels to the DataFrame\n",
    "    dataframe['negative_score'] = negative_scores\n",
    "    dataframe['neutral_score'] = neutral_scores\n",
    "    dataframe['positive_score'] = positive_scores\n",
    "    dataframe['initial_sentiment'] = initial_sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(df, outfilepath):\n",
    "    \"\"\"\n",
    "    Saves the labeled dataframe to GCP data bucket\n",
    "    \n",
    "    Input: Pandas dataframe, GCP file path\n",
    "    Output: None\n",
    "\n",
    "    >>> save_dataset(dataframe, 'filepath'):\n",
    "    returns None\n",
    "    \"\"\"\n",
    "    #convert DataFrame to a CSV string\n",
    "    csv_string = df.to_csv(index=False)\n",
    "\n",
    "    #upload the CSV string to GCP\n",
    "    blob = data_bucket.blob(outfilepath)\n",
    "    blob.upload_from_string(csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "try: \n",
    "    tokenizer, model = get_model(models_bucket.blob(MODEL_DIR_FINETUNE))\n",
    "except:\n",
    "    tokenizer, model = get_model(MODEL_DIR_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>party</th>\n",
       "      <th>network</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>initial_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>20230928</td>\n",
       "      <td>- which is donald trump? what the re which is ...</td>\n",
       "      <td>0.796101</td>\n",
       "      <td>0.147924</td>\n",
       "      <td>0.055975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>MSNBCW</td>\n",
       "      <td>20230927</td>\n",
       "      <td>work for donald trump. you have a different pe...</td>\n",
       "      <td>0.845434</td>\n",
       "      <td>0.112779</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>20230928</td>\n",
       "      <td>donald trump is missing in action. he should b...</td>\n",
       "      <td>0.783439</td>\n",
       "      <td>0.165321</td>\n",
       "      <td>0.051240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>20230927</td>\n",
       "      <td>this isnt about donald trump. donald trump is ...</td>\n",
       "      <td>0.821460</td>\n",
       "      <td>0.130095</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>20230926</td>\n",
       "      <td>hutchinson tells me donald trump, quote, donal...</td>\n",
       "      <td>0.717126</td>\n",
       "      <td>0.193324</td>\n",
       "      <td>0.089550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first   last party  network      date  \\\n",
       "6   Donald  Trump     R  BBCNEWS  20230928   \n",
       "8   Donald  Trump     R   MSNBCW  20230927   \n",
       "9   Donald  Trump     R     CNNW  20230928   \n",
       "15  Donald  Trump     R     CNNW  20230927   \n",
       "33  Donald  Trump     R     CNNW  20230926   \n",
       "\n",
       "                                                 text  negative_score  \\\n",
       "6   - which is donald trump? what the re which is ...        0.796101   \n",
       "8   work for donald trump. you have a different pe...        0.845434   \n",
       "9   donald trump is missing in action. he should b...        0.783439   \n",
       "15  this isnt about donald trump. donald trump is ...        0.821460   \n",
       "33  hutchinson tells me donald trump, quote, donal...        0.717126   \n",
       "\n",
       "    neutral_score  positive_score  initial_sentiment  \n",
       "6        0.147924        0.055975                  0  \n",
       "8        0.112779        0.041787                  0  \n",
       "9        0.165321        0.051240                  0  \n",
       "15       0.130095        0.048446                  0  \n",
       "33       0.193324        0.089550                  0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import labeled dataset \n",
    "initial_df = pd.read_csv(io.StringIO(content))\n",
    "\n",
    "# Filter high-confidence examples based on predicted sentiment scores\n",
    "high_confidence_df = get_high_confidence_df(initial_df, HIGH_CONFIDENCE_THRESHOLD)\n",
    "high_confidence_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Get training and validation datasets \n",
    "train_data, valid_data = get_datasets(high_confidence_df, tokenizer, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: Validation Loss: 0.0681, Validation Accuracy: 0.9880\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the BERT model\n",
    "train_bert(model, train_data, valid_data, device, epochs=NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model to GCP\n",
    "save_model(MODEL_DIR_FINETUNE, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling: 100%|██████████| 115/115 [01:09<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text from initial dataframe\n",
    "tokenized_texts = tokenize(initial_df)\n",
    "\n",
    "# Label the full dataset using the fine-tuned model\n",
    "label(tokenized_texts, model, device, initial_df, batch_size=LABEL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>party</th>\n",
       "      <th>network</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>initial_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>20230928</td>\n",
       "      <td>a second donald trump term would be donald tru...</td>\n",
       "      <td>0.996725</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>20230928</td>\n",
       "      <td>by name this time.  donald trump is missing in...</td>\n",
       "      <td>0.996772</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>MSNBCW</td>\n",
       "      <td>20230926</td>\n",
       "      <td>that cuts at who donald trump is. when he flew...</td>\n",
       "      <td>0.996843</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>20230928</td>\n",
       "      <td>donald trump is a part _ through donald trump?...</td>\n",
       "      <td>0.996895</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Trump</td>\n",
       "      <td>R</td>\n",
       "      <td>CNNW</td>\n",
       "      <td>20230927</td>\n",
       "      <td>when you think of donald trump being the front...</td>\n",
       "      <td>0.996897</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first   last party  network      date  \\\n",
       "0  Donald  Trump     R  BBCNEWS  20230928   \n",
       "1  Donald  Trump     R     CNNW  20230928   \n",
       "2  Donald  Trump     R   MSNBCW  20230926   \n",
       "3  Donald  Trump     R  BBCNEWS  20230928   \n",
       "4  Donald  Trump     R     CNNW  20230927   \n",
       "\n",
       "                                                text  negative_score  \\\n",
       "0  a second donald trump term would be donald tru...        0.996725   \n",
       "1  by name this time.  donald trump is missing in...        0.996772   \n",
       "2  that cuts at who donald trump is. when he flew...        0.996843   \n",
       "3  donald trump is a part _ through donald trump?...        0.996895   \n",
       "4  when you think of donald trump being the front...        0.996897   \n",
       "\n",
       "   neutral_score  positive_score  initial_sentiment  \n",
       "0       0.001229        0.002046                  0  \n",
       "1       0.001228        0.002000                  0  \n",
       "2       0.001190        0.001966                  0  \n",
       "3       0.001167        0.001938                  0  \n",
       "4       0.001194        0.001909                  0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "initial_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final dataframe to GCP\n",
    "save_dataset(initial_df, GCP_OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
