{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertForSequenceClassification, BertTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.functional import softmax\n",
    "from google.cloud import storage \n",
    "import io\n",
    "import tempfile\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare global variables\n",
    "GCP_KEY = '/home/jupyter/secrets/ac215.json'\n",
    "WANDB_FILE = '/home/jupyter/secrets/wandb.txt'\n",
    "GCP_DATA_BUCKET = 'data-lnt'\n",
    "GCP_MODELS_BUCKET = 'models-lnt'\n",
    "GCP_SOURCE_FILENAME = 'processed/vader_labeled_initial.csv'\n",
    "MODEL_SPECIFICATION = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "OUTPUT_FILEPATH = 'processed/labeled.csv'\n",
    "MODEL_DIR_FINETUNE = 'fine_tune_label'\n",
    "\n",
    "HIGH_CONFIDENCE_THRESHOLD = 0.9\n",
    "TEST_SIZE = 0.2\n",
    "NUMBER_EPOCHS = 1\n",
    "RANDOM_STATE = 215\n",
    "ADAM_LEARNING_RATE = 1e-5\n",
    "ADAM_BATCH_SIZE = 32\n",
    "LABEL_BATCH_SIZE = 32\n",
    "PATIENCE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create GCP Client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GCP_KEY\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(GCP_DATA_BUCKET)\n",
    "source_filename = GCP_SOURCE_FILENAME\n",
    "blob = bucket.blob(source_filename)\n",
    "content = blob.download_as_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to the first available GPU\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    # If no GPU is available, use the CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukestoner\u001b[0m (\u001b[33mlnt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/AC215_LNT/src/bert_label/wandb/run-20231024_201651-qt02a8l3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lnt/lnt-bert/runs/qt02a8l3' target=\"_blank\">iconic-river-1</a></strong> to <a href='https://wandb.ai/lnt/lnt-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lnt/lnt-bert' target=\"_blank\">https://wandb.ai/lnt/lnt-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lnt/lnt-bert/runs/qt02a8l3' target=\"_blank\">https://wandb.ai/lnt/lnt-bert/runs/qt02a8l3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lnt/lnt-bert/runs/qt02a8l3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0386e0bf10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# login to weights and biases\n",
    "with open(WANDB_FILE, 'r') as file:\n",
    "    WANDB_KEY = file.read()\n",
    "    \n",
    "wandb.login(key=WANDB_KEY)\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"lnt-bert\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": ADAM_LEARNING_RATE,\n",
    "    \"architecture\": \"BERT\",\n",
    "    \"dataset\": GCP_SOURCE_FILENAME,\n",
    "    \"epochs\": NUMBER_EPOCHS,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    \"\"\"\n",
    "    Input: model_name (name of desired BERT model)\n",
    "    Output: tokenizer, model\n",
    "\n",
    "    >>> get_model(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "    tokenizer(model_name), model(model_name)\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(dataframe):\n",
    "    \"\"\"\n",
    "    Input: Pandas dataframe (assumes text column = 'text')\n",
    "    Output: tokenized text\n",
    "\n",
    "    >>> tokenize(df)\n",
    "    tokenized_texts\n",
    "    \"\"\"\n",
    "    text_samples = dataframe['text'].tolist()\n",
    "    tokenized_texts = tokenizer(text_samples, padding=True, return_tensors='pt')\n",
    "\n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(df, labels, tokenizer, test_size=TEST_SIZE):\n",
    "    \"\"\"\n",
    "    Returns training and validation datasets given a dataframe and tokenizer\n",
    "\n",
    "    Input: panadas dataframe, labels column, tokenizer, test size\n",
    "    Output: tokenized text\n",
    "\n",
    "    >>> tokenize(df)\n",
    "    tokenized_texts\n",
    "    \"\"\"\n",
    "    # Define training and valid dataframes\n",
    "    train_df, valid_df = train_test_split(df, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Tokenize the training data\n",
    "    train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "    train_labels = torch.tensor(train_df[labels].tolist())\n",
    "\n",
    "    # Tokenize the validation data\n",
    "    valid_encodings = tokenizer(valid_df['text'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "    valid_labels = torch.tensor(valid_df[labels].tolist())\n",
    "\n",
    "    # Create DataLoader objects\n",
    "    train_dataset = TensorDataset(train_encodings.input_ids, train_encodings.attention_mask, train_labels)\n",
    "    valid_dataset = TensorDataset(valid_encodings.input_ids, valid_encodings.attention_mask, valid_labels)\n",
    "\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_initial(model, train_dataset, valid_dataset, device, epochs=NUMBER_EPOCHS, patience=5):\n",
    "    \"\"\"\n",
    "    Fine tunes the pretrained BERT model based on the provided labeled datasets\n",
    "\n",
    "    Input: BERT model, training dataset, validation dataset, number of epochs, patience\n",
    "    Output: None (Prints epoch progress)\n",
    "\n",
    "    >>> train_bert(high_confidence_df, train_data, valid_data, epochs=4, patience=5)\n",
    "    Epoch 2/4: Validation Loss: 12.3452, Validation Accuracy: 0.8362\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables for early stopping\n",
    "    best_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "    \n",
    "    # Train loop\n",
    "    optimizer = AdamW(model.parameters(), lr=ADAM_LEARNING_RATE)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=ADAM_BATCH_SIZE, shuffle=True)\n",
    "    num_batches = round((len(train_dataset) / ADAM_BATCH_SIZE) * .25)\n",
    "    batches_trained = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            batches_trained += 1\n",
    "            if batches_trained > num_batches:\n",
    "                break\n",
    "\n",
    "        # Validation loop\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=ADAM_BATCH_SIZE)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch in valid_loader:\n",
    "                input_ids, attention_mask, labels = batch\n",
    "                input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(logits, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            accuracy = correct / total\n",
    "            average_loss = total_loss / len(valid_loader)\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{epochs}: Validation Loss: {average_loss:.4f}, Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "            # Check for early stopping\n",
    "            if average_loss < best_loss:\n",
    "                best_loss = average_loss\n",
    "                no_improvement = 0\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "\n",
    "            if no_improvement >= patience:\n",
    "                print(f'Early stopping after {epoch + 1} epochs without improvement.')\n",
    "                break  # Stop training\n",
    "\n",
    "    print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(tokenized_texts, model, device, dataframe, batch_size=64):\n",
    "    \"\"\"\n",
    "    Uses the BERT model to evaluate the unlabeled dataset. Sentiment scores and labels are added \n",
    "    to the dataframe based on the label provided by the model.\n",
    "\n",
    "    Input: tokenized_texts, model, device, dataframe, batch_size\n",
    "    Output: None\n",
    "    \"\"\"  \n",
    "    #get input IDs and attention mask from tokenized text\n",
    "    input_ids = tokenized_texts['input_ids'].to(device)\n",
    "    attention_mask = tokenized_texts['attention_mask'].to(device)\n",
    "    \n",
    "    #define dataset from input IDs and attention mask\n",
    "    dataset = TensorDataset(input_ids, attention_mask)\n",
    "\n",
    "    #define batch size and create DataLoader\n",
    "    batch_size = batch_size\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    #set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    #create empty list to store labels for entire dataset\n",
    "    labels = []\n",
    "    \n",
    "    #create a progress bar to track labeling process\n",
    "    progress_bar = tqdm(total=len(dataloader), desc=\"Labeling\")\n",
    "    \n",
    "    for batch_input_ids, batch_attention_mask in dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        \n",
    "        #get output logits and convert to label confidence\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        #append batch labels to dataset label list\n",
    "        batch_labels = torch.softmax(logits, dim=1)\n",
    "        labels.append(batch_labels)\n",
    "        \n",
    "        #update progress bar\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    #concatenate all labels\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    #move labels to CPU to append to dataframe\n",
    "    labels = labels.cpu()\n",
    "    \n",
    "    #extract the raw scores for each sentiment class\n",
    "    negative_scores = [score[0].item() for score in labels]\n",
    "    neutral_scores = [score[1].item() for score in labels]\n",
    "    positive_scores = [score[2].item() for score in labels]\n",
    "    \n",
    "    #define final sentiment label my max of sentiment scores\n",
    "    sentiment = []\n",
    "    for neg, neut, pos in zip(negative_scores, neutral_scores, positive_scores):\n",
    "        sentiment.append([neg, neut, pos].index(max([neg, neut, pos])))\n",
    "\n",
    "    #append the scores and predicted labels to the DataFrame\n",
    "    dataframe['negative_score'] = negative_scores\n",
    "    dataframe['neutral_score'] = neutral_scores\n",
    "    dataframe['positive_score'] = positive_scores\n",
    "    dataframe['label'] = sentiment\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_confidence_df(df, threshold=HIGH_CONFIDENCE_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Filters an input dataframe to only include samples with label confidence above a defined threshold\n",
    "\n",
    "    Input: dataframe with initial labels, desired confidence threshold\n",
    "    Output: dataframe including only high confidence examples above specified threshold\n",
    "\n",
    "    >>> get_high_confidence_df(df, 0.9)\n",
    "    high_confidence_df\n",
    "    \"\"\"\n",
    "    return df[(df['negative_score'] > threshold) |\n",
    "    (df['neutral_score'] > threshold) |\n",
    "    (df['positive_score'] > threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final(model, train_dataset, valid_dataset, device, epochs=NUMBER_EPOCHS):\n",
    "    \"\"\"\n",
    "    Fine tunes the pretrained BERT model based on the high confidence samples\n",
    "\n",
    "    Input: BERT model, training dataset, validation dataset, number of epochs\n",
    "    Output: None (Prints epoch progress)\n",
    "\n",
    "    >>> train_bert(high_confidence_df, train_data, valid_data, epochs=4)\n",
    "    Epoch 2/4: Validation Loss: 12.3452, Validation Accuracy: 0.8362\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train loop\n",
    "    optimizer = AdamW(model.parameters(), lr=ADAM_LEARNING_RATE)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=ADAM_BATCH_SIZE, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Validation loop\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=ADAM_BATCH_SIZE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in valid_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        average_loss = total_loss / len(valid_loader)\n",
    "        \n",
    "        # log metrics to wandb\n",
    "        wandb.log({\"acc\": accuracy, \"loss\": average_loss})\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}: Validation Loss: {average_loss:.4f}, Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(df, outfilepath):\n",
    "    \"\"\"\n",
    "    Saves the labeled dataframe to GCP data bucket\n",
    "    \n",
    "    Input: Pandas dataframe, GCP file path\n",
    "    Output: None\n",
    "\n",
    "    >>> save_dataset(dataframe, 'filepath'):\n",
    "    returns None\n",
    "    \"\"\"\n",
    "    #convert DataFrame to a CSV string\n",
    "    csv_string = df.to_csv(index=False)\n",
    "\n",
    "    #upload the CSV string to GCP\n",
    "    blob = bucket.blob(outfilepath)\n",
    "    blob.upload_from_string(csv_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_directory, models_bucket, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Saves the final fine tuned model and tokenizer to GCP models bucket\n",
    "\n",
    "    Input: GCP output directory, model, tokenizer\n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    # Create a temporary directory\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        \n",
    "        # Serialize and save the model in the temporary directory\n",
    "        model_path = os.path.join(temp_dir, 'model.pth')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Save the tokenizer in the temporary directory\n",
    "        tokenizer.save_pretrained(temp_dir)\n",
    "\n",
    "        # Upload the serialized model to the GCS bucket\n",
    "        bucket = storage_client.bucket(models_bucket)\n",
    "        model_blob = bucket.blob(f'{output_directory}/model.pth')\n",
    "        model_blob.upload_from_filename(model_path)\n",
    "\n",
    "        # Upload the contents of the temporary directory to the GCS bucket\n",
    "        for root, dirs, files in os.walk(temp_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                gcs_path = f'{output_directory}/{os.path.relpath(file_path, start=temp_dir)}'\n",
    "                blob = bucket.blob(gcs_path)\n",
    "                blob.upload_from_filename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import VADER labeled dataset into dataframe\n",
    "VADER_df = pd.read_csv(io.StringIO(content))\n",
    "VADER_df = VADER_df.dropna()\n",
    "#Sanity check\n",
    "VADER_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define BERT model and tokenized text\n",
    "tokenizer, model = get_model(MODEL_SPECIFICATION)\n",
    "tokenized_texts = tokenize(VADER_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training and validation datasets for VADER data\n",
    "train_data_VADER, valid_data_VADER = get_datasets(VADER_df, 'vader_label', tokenizer, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine-tune the BERT model based on VADER labels\n",
    "train_initial(model, train_data_VADER, valid_data_VADER, device, epochs=NUMBER_EPOCHS, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the initial dataframe based on newly trained BERT model\n",
    "label(tokenized_texts, model, device, VADER_df, batch_size=LABEL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter high-confidence examples based on predicted sentiment scores\n",
    "VADER_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_confidence_df = get_high_confidence_df(VADER_df)\n",
    "high_confidence_df.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_confidence_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training and validation datasets for BERT data\n",
    "train_data_BERT, valid_data_BERT = get_datasets(high_confidence_df, 'label', tokenizer, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine-tune the BERT model based on VADER labels\n",
    "train_final(model, train_data_BERT, valid_data_BERT, device, epochs=NUMBER_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final dataframe to store scores and labels\n",
    "final_df = VADER_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the initial dataframe based on newly trained BERT model\n",
    "label(tokenized_texts, model, device, final_df, batch_size=LABEL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check\n",
    "final_df.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save final dataset\n",
    "save_dataset(final_df, OUTPUT_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the fine-tuned model to GCP\n",
    "save_model(MODEL_DIR_FINETUNE, GCP_MODELS_BUCKET, model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
